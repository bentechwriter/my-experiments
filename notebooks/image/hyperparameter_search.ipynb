{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://shared:****@allegroai.jfrog.io/allegroai/api/pypi/public/simple\n",
      "Requirement already up-to-date: pandas==1.0.3 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (1.0.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from pandas==1.0.3) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from pandas==1.0.3) (1.18.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from pandas==1.0.3) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas==1.0.3) (1.15.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://shared:****@allegroai.jfrog.io/allegroai/api/pypi/public/simple\n",
      "Requirement already up-to-date: trains==0.15.0 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (0.15.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.3 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: funcsigs>=1.0 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: Pillow>=4.1.1 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: furl>=2.0.0 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=18.0 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyjwt>=1.6.4 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML>=3.12 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (5.3.1)\n",
      "Requirement already satisfied, skipping upgrade: pathlib2>=2.3.0 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (2.3.5)\n",
      "Requirement already satisfied, skipping upgrade: requests-file>=1.4.2 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (1.5.1)\n",
      "Requirement already satisfied, skipping upgrade: urllib3>=1.21.1 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: jsonmodels>=2.2 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (2.4)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: humanfriendly>=2.1 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (8.2)\n",
      "Requirement already satisfied, skipping upgrade: future>=0.16.0 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.19.5 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (4.46.1)\n",
      "Requirement already satisfied, skipping upgrade: psutil>=3.4.2 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (5.7.0)\n",
      "Requirement already satisfied, skipping upgrade: typing>=3.6.4 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (3.7.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.10 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (1.18.4)\n",
      "Requirement already satisfied, skipping upgrade: plotly>=3.9.0 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (4.8.2)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.20.0 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.11.0 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema>=2.6.0 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from trains==0.15.0) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: orderedmultidict>=1.0.1 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from furl>=2.0.0->trains==0.15.0) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from plotly>=3.9.0->trains==0.15.0) (1.3.3)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from requests>=2.20.0->trains==0.15.0) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from requests>=2.20.0->trains==0.15.0) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from requests>=2.20.0->trains==0.15.0) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from jsonschema>=2.6.0->trains==0.15.0) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from jsonschema>=2.6.0->trains==0.15.0) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from jsonschema>=2.6.0->trains==0.15.0) (47.3.1)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=2.6.0->trains==0.15.0) (3.1.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://shared:****@allegroai.jfrog.io/allegroai/api/pypi/public/simple\n",
      "Requirement already up-to-date: hpbandster==0.7.4 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (0.7.4)\n",
      "Requirement already satisfied, skipping upgrade: statsmodels in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from hpbandster==0.7.4) (0.11.1)\n",
      "Requirement already satisfied, skipping upgrade: ConfigSpace in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from hpbandster==0.7.4) (0.4.13)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from hpbandster==0.7.4) (1.18.4)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from hpbandster==0.7.4) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: serpent in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from hpbandster==0.7.4) (1.30.2)\n",
      "Requirement already satisfied, skipping upgrade: Pyro4 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from hpbandster==0.7.4) (4.80)\n",
      "Requirement already satisfied, skipping upgrade: netifaces in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from hpbandster==0.7.4) (0.10.9)\n",
      "Requirement already satisfied, skipping upgrade: patsy>=0.5 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from statsmodels->hpbandster==0.7.4) (0.5.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: pandas>=0.21 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from statsmodels->hpbandster==0.7.4) (1.0.3)\n",
      "Requirement already satisfied, skipping upgrade: cython in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from ConfigSpace->hpbandster==0.7.4) (0.29.20)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from ConfigSpace->hpbandster==0.7.4) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from patsy>=0.5->statsmodels->hpbandster==0.7.4) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from pandas>=0.21->statsmodels->hpbandster==0.7.4) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages (from pandas>=0.21->statsmodels->hpbandster==0.7.4) (2.8.1)\n"
     ]
    }
   ],
   "source": [
    "# execute this in command line on all machines to be used as workers before initiating the hyperparamer search \n",
    "# ! pip install -U trains-agent==0.15.0\n",
    "# ! trains-agent daemon --queue default\n",
    "\n",
    "# pip install with locked versions\n",
    "! pip install -U pandas==1.0.3\n",
    "! pip install -U trains==0.15.0\n",
    "! pip install -U hpbandster==0.7.4  # Needed only for Bayesian optimization Hyper-Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trains.automation import UniformParameterRange, UniformIntegerParameterRange\n",
    "from trains.automation import RandomSearch, HyperParameterOptimizer\n",
    "from trains.automation.hpbandster import OptimizerBOHB  # Needed only for Bayesian optimization Hyper-Band\n",
    "\n",
    "from trains import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINS Task: overwriting (reusing) task id=1e8d52fbb7fc43fb8f19bbdfa0ffc7cc\n",
      "======> WARNING! UNCOMMITTED CHANGES IN REPOSITORY https://github.com/allegroai/trains.git <======\n",
      "TRAINS results page: https://app.trains-master.hosted.allegro.ai/projects/f21c8fba8c19470f82f2c530058718fd/experiments/1e8d52fbb7fc43fb8f19bbdfa0ffc7cc/output/log\n"
     ]
    }
   ],
   "source": [
    "task = Task.init(project_name='Hyper-Parameter Search', task_name='Hyper-Parameter Optimization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "### Don't forget to replace this default id with your own task id ###\n",
    "#####################################################################\n",
    "TEMPLATE_TASK_ID = 'd8838a8dd5d24f08bb037ca965b7651a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINS new version available: upgrade to v0.15.1 is recommended!\n",
      "TRAINS Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n"
     ]
    }
   ],
   "source": [
    "optimizer = HyperParameterOptimizer(\n",
    "    base_task_id=TEMPLATE_TASK_ID,  # This is the experiment we want to optimize\n",
    "    # here we define the hyper-parameters to optimize\n",
    "    hyper_parameters=[\n",
    "        UniformIntegerParameterRange('number_of_epochs', min_value=5, max_value=15, step_size=1),\n",
    "        UniformIntegerParameterRange('batch_size', min_value=2, max_value=12, step_size=2),\n",
    "        UniformParameterRange('dropout', min_value=0, max_value=0.5, step_size=0.05),\n",
    "        UniformParameterRange('base_lr', min_value=0.0005, max_value=0.01, step_size=0.0005),\n",
    "    ],\n",
    "    # this is the objective metric we want to maximize/minimize\n",
    "    objective_metric_title='accuracy',\n",
    "    objective_metric_series='total',\n",
    "    objective_metric_sign='max',  # maximize or minimize the objective metric\n",
    "    max_number_of_concurrent_tasks=3,  # number of concurrent experiments\n",
    "    # setting optimizer - trains supports GridSearch, RandomSearch or OptimizerBOHB\n",
    "    optimizer_class=OptimizerBOHB,  # can be replaced with OptimizerBOHB\n",
    "    execution_queue='default',  # queue to schedule the experiments for execution\n",
    "    optimization_time_limit=30.,  # time limit for each experiment (optional, ignored by OptimizerBOHB)\n",
    "    pool_period_min=1,  # Check the experiments every x minutes\n",
    "    # set the maximum number of experiments for the optimization.\n",
    "    # OptimizerBOHB sets the total number of iteration as total_max_jobs * max_iteration_per_job\n",
    "    total_max_jobs=12,\n",
    "    # setting OptimizerBOHB configuration (ignored by other optimizers)\n",
    "    min_iteration_per_job=15000,  # minimum number of iterations per experiment, till early stopping\n",
    "    max_iteration_per_job=150000,  # maximum number of iterations per experiment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:17:06 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f11388f51d0; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:9090>\n",
      "16:17:06 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "16:17:06 WORKER: start listening for jobs\n",
      "16:17:06 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f11380849b0; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:9090>\n",
      "16:17:06 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "16:17:06 WORKER: start listening for jobs\n",
      "16:17:06 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x7f1138082c18; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:9090>\n",
      "16:17:06 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "16:17:06 wait_for_workers trying to get the condition\n",
      "16:17:06 WORKER: start listening for jobs\n",
      "16:17:06 DISPATCHER: started the 'discover_worker' thread\n",
      "16:17:06 DISPATCHER: started the 'job_runner' thread\n",
      "16:17:06 DISPATCHER: Pyro daemon running on localhost:40933\n",
      "16:17:06 HBMASTER: only 0 worker(s) available, waiting for at least 3.\n",
      "16:17:06 DISPATCHER: Starting worker discovery\n",
      "16:17:06 DISPATCHER: Found 3 potential workers, 0 currently in the pool.\n",
      "16:17:06 DISPATCHER: discovered new worker, hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.0139711964210944\n",
      "16:17:06 DISPATCHER: discovered new worker, hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.1139711964210944\n",
      "16:17:06 DISPATCHER: discovered new worker, hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.2139711964210944\n",
      "16:17:06 HBMASTER: number of workers changed to 3\n",
      "16:17:06 DISPATCHER: jobs to submit = 0, number of idle workers = 3 -> waiting!\n",
      "16:17:06 adjust_queue_size: lock accquired\n",
      "16:17:06 HBMASTER: adjusted queue size to (2, 3)\n",
      "16:17:06 DISPATCHER: Finished worker discovery\n",
      "16:17:06 DISPATCHER: A new worker triggered discover_worker\n",
      "16:17:06 DISPATCHER: Trying to submit another job.\n",
      "16:17:06 DISPATCHER: jobs to submit = 0, number of idle workers = 3 -> waiting!\n",
      "16:17:06 Enough workers to start this run!\n",
      "16:17:06 HBMASTER: starting run at 1593350226.6047654\n",
      "16:17:06 start sampling a new configuration.\n",
      "16:17:06 done sampling a new configuration.\n",
      "16:17:06 HBMASTER: schedule new run for iteration 0\n",
      "16:17:06 HBMASTER: trying submitting job (0, 0, 0) to dispatcher\n",
      "16:17:06 HBMASTER: submitting job (0, 0, 0) to dispatcher\n",
      "16:17:06 DISPATCHER: trying to submit job (0, 0, 0)\n",
      "16:17:06 DISPATCHER: Starting worker discovery\n",
      "16:17:06 DISPATCHER: Found 3 potential workers, 3 currently in the pool.\n",
      "16:17:06 DISPATCHER: Finished worker discovery\n",
      "16:17:06 DISPATCHER: trying to notify the job_runner thread.\n",
      "16:17:06 HBMASTER: job (0, 0, 0) submitted to dispatcher\n",
      "16:17:06 start sampling a new configuration.\n",
      "16:17:06 done sampling a new configuration.\n",
      "16:17:06 HBMASTER: schedule new run for iteration 0\n",
      "16:17:06 HBMASTER: trying submitting job (0, 0, 1) to dispatcher\n",
      "16:17:06 HBMASTER: submitting job (0, 0, 1) to dispatcher\n",
      "16:17:06 DISPATCHER: trying to submit job (0, 0, 1)\n",
      "16:17:06 DISPATCHER: Trying to submit another job.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress report #0 completed, sleeping for 0.25 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:17:06 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.0139711964210944\n",
      "16:17:06 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.0139711964210944\n",
      "16:17:06 DISPATCHER: jobs to submit = 0, number of idle workers = 2 -> waiting!\n",
      "16:17:06 DISPATCHER: trying to notify the job_runner thread.\n",
      "16:17:06 HBMASTER: job (0, 0, 1) submitted to dispatcher\n",
      "16:17:06 start sampling a new configuration.\n",
      "16:17:06 done sampling a new configuration.\n",
      "16:17:06 HBMASTER: schedule new run for iteration 0\n",
      "16:17:06 HBMASTER: trying submitting job (0, 0, 2) to dispatcher\n",
      "16:17:06 HBMASTER: submitting job (0, 0, 2) to dispatcher\n",
      "16:17:06 DISPATCHER: trying to submit job (0, 0, 2)\n",
      "16:17:06 DISPATCHER: Trying to submit another job.\n",
      "16:17:06 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.2139711964210944\n",
      "16:17:06 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.2139711964210944\n",
      "16:17:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "16:17:06 WORKER: start processing job (0, 0, 0)\n",
      "16:17:06 WORKER: args: ()\n",
      "16:17:06 WORKER: kwargs: {'config': {'base_lr': 0.003, 'batch_size': 4, 'dropout': 0.15000000000000002, 'number_of_epochs': 10}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n",
      "16:17:06 WORKER: start processing job (0, 0, 1)\n",
      "16:17:06 DISPATCHER: trying to notify the job_runner thread.\n",
      "16:17:06 HBMASTER: job (0, 0, 2) submitted to dispatcher\n",
      "16:17:06 HBMASTER: running jobs: 3, queue sizes: (2, 3) -> wait\n",
      "16:17:06 WORKER: args: ()\n",
      "16:17:06 WORKER: kwargs: {'config': {'base_lr': 0.0035, 'batch_size': 8, 'dropout': 0.1, 'number_of_epochs': 15}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n",
      "16:17:06 DISPATCHER: Trying to submit another job.\n",
      "16:17:06 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.1139711964210944\n",
      "16:17:06 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.1139711964210944\n",
      "16:17:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "16:17:06 WORKER: start processing job (0, 0, 2)\n",
      "16:17:06 WORKER: args: ()\n",
      "16:17:06 WORKER: kwargs: {'config': {'base_lr': 0.0075, 'batch_size': 2, 'dropout': 0.2, 'number_of_epochs': 11}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-28 16:17:08,519 - trains.automation.optimization - INFO - Creating new Task: {'base_lr': 0.003, 'batch_size': 4, 'dropout': 0.15000000000000002, 'number_of_epochs': 10}\n",
      "2020-06-28 16:17:08,545 - trains.automation.optimization - INFO - Creating new Task: {'base_lr': 0.0035, 'batch_size': 8, 'dropout': 0.1, 'number_of_epochs': 15}\n",
      "2020-06-28 16:17:08,649 - trains.automation.optimization - INFO - Creating new Task: {'base_lr': 0.0075, 'batch_size': 2, 'dropout': 0.2, 'number_of_epochs': 11}\n",
      "Progress report #1 completed, sleeping for 5.0 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:18:06 DISPATCHER: Starting worker discovery\n",
      "16:18:06 DISPATCHER: Found 3 potential workers, 3 currently in the pool.\n",
      "16:18:06 DISPATCHER: Finished worker discovery\n",
      "16:19:06 DISPATCHER: Starting worker discovery\n",
      "16:19:06 DISPATCHER: Found 3 potential workers, 3 currently in the pool.\n",
      "16:19:06 DISPATCHER: Finished worker discovery\n",
      "16:20:06 DISPATCHER: Starting worker discovery\n",
      "16:20:06 DISPATCHER: Found 3 potential workers, 3 currently in the pool.\n",
      "16:20:06 DISPATCHER: Finished worker discovery\n",
      "16:21:06 DISPATCHER: Starting worker discovery\n",
      "16:21:06 DISPATCHER: Found 3 potential workers, 3 currently in the pool.\n",
      "16:21:06 DISPATCHER: Finished worker discovery\n",
      "16:22:06 DISPATCHER: Starting worker discovery\n",
      "16:22:06 DISPATCHER: Found 3 potential workers, 3 currently in the pool.\n",
      "16:22:06 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress report #2 completed, sleeping for 5.0 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:23:06 DISPATCHER: Starting worker discovery\n",
      "16:23:06 DISPATCHER: Found 3 potential workers, 3 currently in the pool.\n",
      "16:23:06 DISPATCHER: Finished worker discovery\n",
      "16:24:06 DISPATCHER: Starting worker discovery\n",
      "16:24:06 DISPATCHER: Found 3 potential workers, 3 currently in the pool.\n",
      "16:24:06 DISPATCHER: Finished worker discovery\n",
      "16:24:13 WORKER: done with job (0, 0, 0), trying to register it.\n",
      "16:24:13 WORKER: registered result for job (0, 0, 0) with dispatcher\n",
      "16:24:13 DISPATCHER: job (0, 0, 0) finished\n",
      "16:24:13 DISPATCHER: register_result: lock acquired\n",
      "16:24:13 DISPATCHER: job (0, 0, 0) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.0139711964210944 finished\n",
      "16:24:13 job_id: (0, 0, 0)\n",
      "kwargs: {'config': {'base_lr': 0.003, 'batch_size': 4, 'dropout': 0.15000000000000002, 'number_of_epochs': 10}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/trains/automation/hpbandster/bandster.py\", line 102, in compute\n",
      "    'loss': float(self.objective.get_normalized_objective(self._current_job) * -1.),\n",
      "TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'\n",
      "\n",
      "\n",
      "16:24:13 job_callback for (0, 0, 0) started\n",
      "16:24:13 DISPATCHER: Trying to submit another job.\n",
      "16:24:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "16:24:13 job_callback for (0, 0, 0) got condition\n",
      "16:24:13 job (0, 0, 0) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/trains/automation/hpbandster/bandster.py\", line 102, in compute\n",
      "    'loss': float(self.objective.get_normalized_objective(self._current_job) * -1.),\n",
      "TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'\n",
      "\n",
      "16:24:13 Only 1 run(s) for budget 0.111111 available, need more than 6 -> can't build model!\n",
      "16:24:13 HBMASTER: Trying to run another job!\n",
      "16:24:13 job_callback for (0, 0, 0) finished\n",
      "16:24:13 start sampling a new configuration.\n",
      "16:24:13 done sampling a new configuration.\n",
      "16:24:13 HBMASTER: schedule new run for iteration 0\n",
      "16:24:13 HBMASTER: trying submitting job (0, 0, 3) to dispatcher\n",
      "16:24:13 HBMASTER: submitting job (0, 0, 3) to dispatcher\n",
      "16:24:13 DISPATCHER: trying to submit job (0, 0, 3)\n",
      "16:24:13 DISPATCHER: trying to notify the job_runner thread.\n",
      "16:24:13 HBMASTER: job (0, 0, 3) submitted to dispatcher\n",
      "16:24:13 HBMASTER: running jobs: 3, queue sizes: (2, 3) -> wait\n",
      "16:24:13 DISPATCHER: Trying to submit another job.\n",
      "16:24:13 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.0139711964210944\n",
      "16:24:13 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.0139711964210944\n",
      "16:24:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "16:24:13 WORKER: start processing job (0, 0, 3)\n",
      "16:24:13 WORKER: args: ()\n",
      "16:24:13 WORKER: kwargs: {'config': {'base_lr': 0.0015, 'batch_size': 12, 'dropout': 0.2, 'number_of_epochs': 13}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n",
      "16:24:15 WORKER: done with job (0, 0, 1), trying to register it.\n",
      "16:24:15 WORKER: registered result for job (0, 0, 1) with dispatcher\n",
      "16:24:15 DISPATCHER: job (0, 0, 1) finished\n",
      "16:24:15 DISPATCHER: register_result: lock acquired\n",
      "16:24:15 DISPATCHER: job (0, 0, 1) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.2139711964210944 finished\n",
      "16:24:15 job_id: (0, 0, 1)\n",
      "kwargs: {'config': {'base_lr': 0.0035, 'batch_size': 8, 'dropout': 0.1, 'number_of_epochs': 15}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/trains/automation/hpbandster/bandster.py\", line 102, in compute\n",
      "    'loss': float(self.objective.get_normalized_objective(self._current_job) * -1.),\n",
      "TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'\n",
      "\n",
      "\n",
      "16:24:15 job_callback for (0, 0, 1) started\n",
      "16:24:15 DISPATCHER: Trying to submit another job.\n",
      "16:24:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "16:24:15 job_callback for (0, 0, 1) got condition\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-28 16:24:15,409 - trains.automation.optimization - INFO - Creating new Task: {'base_lr': 0.0015, 'batch_size': 12, 'dropout': 0.2, 'number_of_epochs': 13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:24:15 job (0, 0, 1) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/trains/automation/hpbandster/bandster.py\", line 102, in compute\n",
      "    'loss': float(self.objective.get_normalized_objective(self._current_job) * -1.),\n",
      "TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'\n",
      "\n",
      "16:24:15 Only 2 run(s) for budget 0.111111 available, need more than 6 -> can't build model!\n",
      "16:24:15 HBMASTER: Trying to run another job!\n",
      "16:24:15 job_callback for (0, 0, 1) finished\n",
      "16:24:15 start sampling a new configuration.\n",
      "16:24:15 done sampling a new configuration.\n",
      "16:24:15 HBMASTER: schedule new run for iteration 0\n",
      "16:24:15 HBMASTER: trying submitting job (0, 0, 4) to dispatcher\n",
      "16:24:15 HBMASTER: submitting job (0, 0, 4) to dispatcher\n",
      "16:24:15 DISPATCHER: trying to submit job (0, 0, 4)\n",
      "16:24:15 DISPATCHER: trying to notify the job_runner thread.\n",
      "16:24:15 HBMASTER: job (0, 0, 4) submitted to dispatcher\n",
      "16:24:15 HBMASTER: running jobs: 3, queue sizes: (2, 3) -> wait\n",
      "16:24:15 DISPATCHER: Trying to submit another job.\n",
      "16:24:15 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.2139711964210944\n",
      "16:24:15 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.2139711964210944\n",
      "16:24:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "16:24:15 WORKER: start processing job (0, 0, 4)\n",
      "16:24:15 WORKER: args: ()\n",
      "16:24:15 WORKER: kwargs: {'config': {'base_lr': 0.008, 'batch_size': 6, 'dropout': 0.2, 'number_of_epochs': 11}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-28 16:24:17,397 - trains.automation.optimization - INFO - Creating new Task: {'base_lr': 0.008, 'batch_size': 6, 'dropout': 0.2, 'number_of_epochs': 11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:25:06 DISPATCHER: Starting worker discovery\n",
      "16:25:06 DISPATCHER: Found 3 potential workers, 3 currently in the pool.\n",
      "16:25:06 DISPATCHER: Finished worker discovery\n",
      "16:25:15 WORKER: done with job (0, 0, 2), trying to register it.\n",
      "16:25:15 WORKER: registered result for job (0, 0, 2) with dispatcher\n",
      "16:25:15 DISPATCHER: job (0, 0, 2) finished\n",
      "16:25:15 DISPATCHER: register_result: lock acquired\n",
      "16:25:15 DISPATCHER: job (0, 0, 2) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.1139711964210944 finished\n",
      "16:25:15 job_id: (0, 0, 2)\n",
      "kwargs: {'config': {'base_lr': 0.0075, 'batch_size': 2, 'dropout': 0.2, 'number_of_epochs': 11}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/trains/automation/hpbandster/bandster.py\", line 102, in compute\n",
      "    'loss': float(self.objective.get_normalized_objective(self._current_job) * -1.),\n",
      "TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'\n",
      "\n",
      "\n",
      "16:25:15 job_callback for (0, 0, 2) started\n",
      "16:25:15 DISPATCHER: Trying to submit another job.\n",
      "16:25:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "16:25:15 job_callback for (0, 0, 2) got condition\n",
      "16:25:16 job (0, 0, 2) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/trains/automation/hpbandster/bandster.py\", line 102, in compute\n",
      "    'loss': float(self.objective.get_normalized_objective(self._current_job) * -1.),\n",
      "TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'\n",
      "\n",
      "16:25:16 Only 3 run(s) for budget 0.111111 available, need more than 6 -> can't build model!\n",
      "16:25:16 HBMASTER: Trying to run another job!\n",
      "16:25:16 job_callback for (0, 0, 2) finished\n",
      "16:25:16 start sampling a new configuration.\n",
      "16:25:16 done sampling a new configuration.\n",
      "16:25:16 HBMASTER: schedule new run for iteration 0\n",
      "16:25:16 HBMASTER: trying submitting job (0, 0, 5) to dispatcher\n",
      "16:25:16 HBMASTER: submitting job (0, 0, 5) to dispatcher\n",
      "16:25:16 DISPATCHER: trying to submit job (0, 0, 5)\n",
      "16:25:16 DISPATCHER: trying to notify the job_runner thread.\n",
      "16:25:16 HBMASTER: job (0, 0, 5) submitted to dispatcher\n",
      "16:25:16 HBMASTER: running jobs: 3, queue sizes: (2, 3) -> wait\n",
      "16:25:16 DISPATCHER: Trying to submit another job.\n",
      "16:25:16 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.1139711964210944\n",
      "16:25:16 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.1139711964210944\n",
      "16:25:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "16:25:16 WORKER: start processing job (0, 0, 5)\n",
      "16:25:16 WORKER: args: ()\n",
      "16:25:16 WORKER: kwargs: {'config': {'base_lr': 0.008, 'batch_size': 4, 'dropout': 0.15000000000000002, 'number_of_epochs': 12}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n",
      "16:25:17 WORKER: done with job (0, 0, 3), trying to register it.\n",
      "16:25:17 WORKER: registered result for job (0, 0, 3) with dispatcher\n",
      "16:25:17 DISPATCHER: job (0, 0, 3) finished\n",
      "16:25:17 DISPATCHER: register_result: lock acquired\n",
      "16:25:17 DISPATCHER: job (0, 0, 3) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.0139711964210944 finished\n",
      "16:25:17 job_id: (0, 0, 3)\n",
      "kwargs: {'config': {'base_lr': 0.0015, 'batch_size': 12, 'dropout': 0.2, 'number_of_epochs': 13}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/trains/automation/hpbandster/bandster.py\", line 102, in compute\n",
      "    'loss': float(self.objective.get_normalized_objective(self._current_job) * -1.),\n",
      "TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'\n",
      "\n",
      "\n",
      "16:25:17 job_callback for (0, 0, 3) started\n",
      "16:25:17 DISPATCHER: Trying to submit another job.\n",
      "16:25:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "16:25:17 job_callback for (0, 0, 3) got condition\n",
      "16:25:17 job (0, 0, 3) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/trains/automation/hpbandster/bandster.py\", line 102, in compute\n",
      "    'loss': float(self.objective.get_normalized_objective(self._current_job) * -1.),\n",
      "TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'\n",
      "\n",
      "16:25:17 Only 4 run(s) for budget 0.111111 available, need more than 6 -> can't build model!\n",
      "16:25:17 HBMASTER: Trying to run another job!\n",
      "16:25:17 job_callback for (0, 0, 3) finished\n",
      "16:25:17 start sampling a new configuration.\n",
      "16:25:17 done sampling a new configuration.\n",
      "16:25:17 HBMASTER: schedule new run for iteration 0\n",
      "16:25:17 HBMASTER: trying submitting job (0, 0, 6) to dispatcher\n",
      "16:25:17 HBMASTER: submitting job (0, 0, 6) to dispatcher\n",
      "16:25:17 DISPATCHER: trying to submit job (0, 0, 6)\n",
      "16:25:17 DISPATCHER: trying to notify the job_runner thread.\n",
      "16:25:17 HBMASTER: job (0, 0, 6) submitted to dispatcher\n",
      "16:25:17 HBMASTER: running jobs: 3, queue sizes: (2, 3) -> wait\n",
      "16:25:17 DISPATCHER: Trying to submit another job.\n",
      "16:25:17 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.0139711964210944\n",
      "16:25:17 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.0139711964210944\n",
      "16:25:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "16:25:17 WORKER: start processing job (0, 0, 6)\n",
      "16:25:17 WORKER: args: ()\n",
      "16:25:17 WORKER: kwargs: {'config': {'base_lr': 0.005000000000000001, 'batch_size': 4, 'dropout': 0.2, 'number_of_epochs': 7}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-28 16:25:18,511 - trains.automation.optimization - INFO - Creating new Task: {'base_lr': 0.008, 'batch_size': 4, 'dropout': 0.15000000000000002, 'number_of_epochs': 12}\n",
      "2020-06-28 16:25:18,851 - trains.automation.optimization - INFO - Creating new Task: {'base_lr': 0.005000000000000001, 'batch_size': 4, 'dropout': 0.2, 'number_of_epochs': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:26:06 DISPATCHER: Starting worker discovery\n",
      "16:26:06 DISPATCHER: Found 3 potential workers, 3 currently in the pool.\n",
      "16:26:06 DISPATCHER: Finished worker discovery\n",
      "16:26:19 WORKER: done with job (0, 0, 4), trying to register it.\n",
      "16:26:19 WORKER: registered result for job (0, 0, 4) with dispatcher\n",
      "16:26:19 DISPATCHER: job (0, 0, 4) finished\n",
      "16:26:19 DISPATCHER: register_result: lock acquired\n",
      "16:26:19 DISPATCHER: job (0, 0, 4) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.2139711964210944 finished\n",
      "16:26:19 job_id: (0, 0, 4)\n",
      "kwargs: {'config': {'base_lr': 0.008, 'batch_size': 6, 'dropout': 0.2, 'number_of_epochs': 11}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/trains/automation/hpbandster/bandster.py\", line 102, in compute\n",
      "    'loss': float(self.objective.get_normalized_objective(self._current_job) * -1.),\n",
      "TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'\n",
      "\n",
      "\n",
      "16:26:19 job_callback for (0, 0, 4) started\n",
      "16:26:19 DISPATCHER: Trying to submit another job.\n",
      "16:26:19 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "16:26:19 job_callback for (0, 0, 4) got condition\n",
      "16:26:19 job (0, 0, 4) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/trains/automation/hpbandster/bandster.py\", line 102, in compute\n",
      "    'loss': float(self.objective.get_normalized_objective(self._current_job) * -1.),\n",
      "TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'\n",
      "\n",
      "16:26:19 HBMASTER: Trying to run another job!\n",
      "16:26:19 job_callback for (0, 0, 4) finished\n",
      "16:26:19 start sampling a new configuration.\n",
      "16:26:19 done sampling a new configuration.\n",
      "16:26:19 HBMASTER: schedule new run for iteration 0\n",
      "16:26:19 HBMASTER: trying submitting job (0, 0, 7) to dispatcher\n",
      "16:26:19 HBMASTER: submitting job (0, 0, 7) to dispatcher\n",
      "16:26:19 DISPATCHER: trying to submit job (0, 0, 7)\n",
      "16:26:19 DISPATCHER: trying to notify the job_runner thread.\n",
      "16:26:19 HBMASTER: job (0, 0, 7) submitted to dispatcher\n",
      "16:26:19 HBMASTER: running jobs: 3, queue sizes: (2, 3) -> wait\n",
      "16:26:19 DISPATCHER: Trying to submit another job.\n",
      "16:26:19 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.2139711964210944\n",
      "16:26:19 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.2139711964210944\n",
      "16:26:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "16:26:19 WORKER: start processing job (0, 0, 7)\n",
      "16:26:19 WORKER: args: ()\n",
      "16:26:19 WORKER: kwargs: {'config': {'base_lr': 0.0055, 'batch_size': 10, 'dropout': 0.1, 'number_of_epochs': 15}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n",
      "16:26:20 WORKER: done with job (0, 0, 5), trying to register it.\n",
      "16:26:20 WORKER: registered result for job (0, 0, 5) with dispatcher\n",
      "16:26:20 WORKER: done with job (0, 0, 6), trying to register it.\n",
      "16:26:20 WORKER: registered result for job (0, 0, 6) with dispatcher\n",
      "16:26:20 DISPATCHER: job (0, 0, 5) finished\n",
      "16:26:20 DISPATCHER: register_result: lock acquired\n",
      "16:26:20 DISPATCHER: job (0, 0, 5) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.1139711964210944 finished\n",
      "16:26:20 job_id: (0, 0, 5)\n",
      "kwargs: {'config': {'base_lr': 0.008, 'batch_size': 4, 'dropout': 0.15000000000000002, 'number_of_epochs': 12}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/trains/automation/hpbandster/bandster.py\", line 102, in compute\n",
      "    'loss': float(self.objective.get_normalized_objective(self._current_job) * -1.),\n",
      "TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'\n",
      "\n",
      "\n",
      "16:26:20 DISPATCHER: job (0, 0, 6) finished\n",
      "16:26:20 DISPATCHER: Trying to submit another job.\n",
      "16:26:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "16:26:20 DISPATCHER: register_result: lock acquired\n",
      "16:26:20 DISPATCHER: job (0, 0, 6) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.0139711964210944 finished\n",
      "16:26:20 job_id: (0, 0, 6)\n",
      "kwargs: {'config': {'base_lr': 0.005000000000000001, 'batch_size': 4, 'dropout': 0.2, 'number_of_epochs': 7}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/trains/automation/hpbandster/bandster.py\", line 102, in compute\n",
      "    'loss': float(self.objective.get_normalized_objective(self._current_job) * -1.),\n",
      "TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'\n",
      "\n",
      "\n",
      "16:26:20 job_callback for (0, 0, 6) started\n",
      "16:26:20 job_callback for (0, 0, 6) got condition\n",
      "16:26:20 job (0, 0, 6) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/trains/automation/hpbandster/bandster.py\", line 102, in compute\n",
      "    'loss': float(self.objective.get_normalized_objective(self._current_job) * -1.),\n",
      "TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'\n",
      "\n",
      "16:26:20 HBMASTER: Trying to run another job!\n",
      "16:26:20 DISPATCHER: Trying to submit another job.\n",
      "16:26:20 job_callback for (0, 0, 5) started\n",
      "16:26:20 start sampling a new configuration.\n",
      "16:26:20 done sampling a new configuration.\n",
      "16:26:20 HBMASTER: schedule new run for iteration 0\n",
      "16:26:20 HBMASTER: trying submitting job (0, 0, 8) to dispatcher\n",
      "16:26:20 HBMASTER: submitting job (0, 0, 8) to dispatcher\n",
      "16:26:20 DISPATCHER: trying to submit job (0, 0, 8)\n",
      "16:26:20 DISPATCHER: jobs to submit = 0, number of idle workers = 2 -> waiting!\n",
      "16:26:20 job_callback for (0, 0, 6) finished\n",
      "16:26:20 DISPATCHER: trying to notify the job_runner thread.\n",
      "16:26:20 HBMASTER: job (0, 0, 8) submitted to dispatcher\n",
      "16:26:20 HBMASTER: running jobs: 3, queue sizes: (2, 3) -> wait\n",
      "16:26:20 DISPATCHER: Trying to submit another job.\n",
      "16:26:20 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.1139711964210944\n",
      "16:26:20 job_callback for (0, 0, 5) got condition\n",
      "16:26:20 job (0, 0, 5) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/hpbandster/core/worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"/home/osboxes/Projects/VirtualEnvs/trains/lib/python3.6/site-packages/trains/automation/hpbandster/bandster.py\", line 102, in compute\n",
      "    'loss': float(self.objective.get_normalized_objective(self._current_job) * -1.),\n",
      "TypeError: unsupported operand type(s) for *: 'NoneType' and 'float'\n",
      "\n",
      "16:26:20 HBMASTER: Trying to run another job!\n",
      "16:26:20 job_callback for (0, 0, 5) finished\n",
      "16:26:20 WORKER: start processing job (0, 0, 8)\n",
      "16:26:20 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.1139711964210944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:26:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "16:26:20 WORKER: args: ()\n",
      "16:26:20 WORKER: kwargs: {'config': {'base_lr': 0.0045000000000000005, 'batch_size': 8, 'dropout': 0.25, 'number_of_epochs': 5}, 'budget': 0.1111111111111111, 'working_directory': '.'}\n",
      "16:26:20 start sampling a new configuration.\n",
      "16:26:20 done sampling a new configuration.\n",
      "16:26:20 HBMASTER: schedule new run for iteration 1\n",
      "16:26:20 HBMASTER: trying submitting job (1, 0, 0) to dispatcher\n",
      "16:26:20 HBMASTER: submitting job (1, 0, 0) to dispatcher\n",
      "16:26:20 DISPATCHER: trying to submit job (1, 0, 0)\n",
      "16:26:20 DISPATCHER: trying to notify the job_runner thread.\n",
      "16:26:20 HBMASTER: job (1, 0, 0) submitted to dispatcher\n",
      "16:26:20 HBMASTER: running jobs: 3, queue sizes: (2, 3) -> wait\n",
      "16:26:20 DISPATCHER: Trying to submit another job.\n",
      "16:26:20 DISPATCHER: starting job (1, 0, 0) on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.0139711964210944\n",
      "16:26:20 DISPATCHER: job (1, 0, 0) dispatched on hpbandster.run_OptimizerBOHB_1593350226.4550233.worker.osboxes.5525.0139711964210944\n",
      "16:26:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "16:26:20 WORKER: start processing job (1, 0, 0)\n",
      "16:26:20 WORKER: args: ()\n",
      "16:26:20 WORKER: kwargs: {'config': {'base_lr': 0.0075, 'batch_size': 12, 'dropout': 0.05, 'number_of_epochs': 6}, 'budget': 0.3333333333333333, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-28 16:26:20,991 - trains.automation.optimization - INFO - Creating new Task: {'base_lr': 0.0055, 'batch_size': 10, 'dropout': 0.1, 'number_of_epochs': 15}\n",
      "2020-06-28 16:26:22,509 - trains.automation.optimization - INFO - Creating new Task: {'base_lr': 0.0045000000000000005, 'batch_size': 8, 'dropout': 0.25, 'number_of_epochs': 5}\n",
      "2020-06-28 16:26:22,533 - trains.automation.optimization - INFO - Creating new Task: {'base_lr': 0.0075, 'batch_size': 12, 'dropout': 0.05, 'number_of_epochs': 6}\n"
     ]
    }
   ],
   "source": [
    "optimizer.set_time_limit(in_minutes=120.0)  # set the time limit for the optimization process\n",
    "optimizer.start()  \n",
    "optimizer.wait()  # wait until process is done\n",
    "optimizer.stop()  # make sure background optimization stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization is completed, print the top performing experiments id\n",
    "k = 3\n",
    "top_exp = optimizer.get_top_experiments(top_k=k)\n",
    "print('Top {} experiments are:'.format(k))\n",
    "for n, t in enumerate(top_exp, 1):\n",
    "    print('Rank {}: task id={} |result={}'\n",
    "          .format(n, t.id, t.get_last_scalar_metrics()['accuracy']['total']['last']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
